{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KbG7IYK_-6lE"
      },
      "outputs": [],
      "source": [
        "#Importing necessary libraries\n",
        "from keras.layers import LSTM, Dense, Embedding\n",
        "from keras.models import Sequential\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "\n",
        "#Try to look for imdb dataset\n",
        "\n",
        "#Get hands-on with this dataset, get more info\n",
        "from keras.datasets import imdb"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Note that below loaded data is already preprocessed.\n",
        "\n",
        "But in usual scenarios you will get tha dataset which contains text data. Following preprocessing techniques can be used:\n",
        "Try to google each of the below pre-processing techniques for more details\n",
        "1. uppercase letters to lower case\n",
        "2. english stopwords removal\n",
        "3. remove unwanted non alpha numeric characters\n",
        "4. remove punctuation marks\n",
        "and many more....\n",
        "\n",
        "\n",
        "Text Embeddings\n",
        "Convert text data to array(numerical form) using one of the following embedding techniques:\n",
        "1. Glove embedding(Global Vectors)\n",
        "2. Word2Vec\n",
        "3. BERT embeddings\n",
        "There are various other online and offline models for embeddings..."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdzPuGaB-7UU"
      },
      "outputs": [],
      "source": [
        "#Load train data - No need to preprocess and not that data is already embedded\n",
        "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=20000)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Why padding?\n",
        "2. maxlen?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Je7pT5x--hq"
      },
      "outputs": [],
      "source": [
        "X_train = sequence.pad_sequences(X_train, maxlen=100)\n",
        "X_test = sequence.pad_sequences(X_test, maxlen=100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. No need to go into details of each of the layers\n",
        "2. Just look at what is sequential, what does .add method do?\n",
        "3. What is dense layer and why to put that layer in end?\n",
        "4. No need to go in details of a LSTM, knowing overview if it is sufficient\n",
        "5. What is dropout?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Try to look for different model architectures that can be used and experiment with it.\n",
        "1. You can use multiple LSTM layer\n",
        "2. You can change the activation function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kGMCajRm_FZu"
      },
      "outputs": [],
      "source": [
        "#Model\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Embedding(20000, 128))\n",
        "model.add(LSTM(128, dropout=0.2, recurrent_dropout=0.2))\n",
        "model.add(Dense(1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. What are optimzers?\n",
        "2. What is confusion matrix"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qYfB_Z5g_G4E"
      },
      "outputs": [],
      "source": [
        "model.compile(loss='binary_crossentropy',\n",
        "              optimizer='adam',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "1. Try to research about the shape (x,) and get the clear understanding of it\n",
        "2. Difference between (x,1) shape and (x,) shape\n",
        "3. Try to get handson with numpy library - very useful"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y_train.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#reshaping\n",
        "y_train = y_train.reshape(25000,1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(y_train.shape)\n",
        "print(X_train.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Try to get the understanding of:\n",
        "1. epochs\n",
        "2. python slicing - different techniques\n",
        "3. training, testing, validation data\n",
        "4. What does below cell do?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "Pm6piNqt_JN8",
        "outputId": "7ddec6c9-9781-4c3d-be98-e0d479f87ad0"
      },
      "outputs": [],
      "source": [
        "#Model training\n",
        "\n",
        "model.fit(X_train[:2500,:], y_train[:2500,:],\n",
        "          batch_size=64,\n",
        "          epochs=10,\n",
        "          verbose=2,\n",
        "          validation_data=(X_test, y_test))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "OcdqixhY_Lip",
        "outputId": "23deda5b-a597-4ffc-83fc-b486b837f1c2"
      },
      "outputs": [],
      "source": [
        "#Predicting score, accuracy\n",
        "score, accuracy = model.evaluate(X_test, y_test, batch_size=32, verbose=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gEZmR8g7_PH6"
      },
      "outputs": [],
      "source": [
        "#Predictions\n",
        "predictions = model.predict(X_test[:5])\n",
        "predictions"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9 (pytorch)",
      "language": "python",
      "name": "pytorch"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
